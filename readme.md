# AbstractManager ç¼“å­˜ç®¡ç†æ¡†æ¶ - ä½¿ç”¨æŒ‡å—

## ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¤ºä¾‹ä»£ç è§£è¯»](#ç¤ºä¾‹ä»£ç è§£è¯»)
- [API æ¥å£è¯¦è§£](#api-æ¥å£è¯¦è§£)
- [è¿‡æ»¤å™¨ç³»ç»Ÿ](#è¿‡æ»¤å™¨ç³»ç»Ÿ)
- [æœªæ¥åŠŸèƒ½é¢„å‘Š](#æœªæ¥åŠŸèƒ½é¢„å‘Š)

---

## é¡¹ç›®æ¦‚è¿°

AbstractManager æ˜¯ä¸€ä¸ªåŸºäº Go çš„ç¼“å­˜ç®¡ç†æ¡†æ¶ï¼Œæ—¨åœ¨ç®€åŒ– Redis ç¼“å­˜ä¸æ•°æ®åº“ä¹‹é—´çš„æ•°æ®åŒæ­¥æ“ä½œã€‚æœ¬æ¡†æ¶æä¾›äº†ï¼š

- **ç»Ÿä¸€çš„ç¼“å­˜å†™å…¥æ¥å£**ï¼šæ”¯æŒå•æ¡ã€æ‰¹é‡ã€ç‰ˆæœ¬åŒ–å†™å…¥
- **çµæ´»çš„ç¼“å­˜æŸ¥è¯¢èƒ½åŠ›**ï¼šæ”¯æŒæ¨¡å¼åŒ¹é…ã€æ¡ä»¶è¿‡æ»¤ã€è‡ªå®šä¹‰ä¸šåŠ¡è¿‡æ»¤å™¨
- **åˆ†å±‚æ¶æ„è®¾è®¡**ï¼šæ¸…æ™°åˆ†ç¦»ç¯å¢ƒåˆå§‹åŒ–ã€åŸºç¡€è®¾æ–½ã€ä¸šåŠ¡æœåŠ¡å’Œ HTTP è·¯ç”±å±‚
- **é«˜æ€§èƒ½æ‰¹é‡æ“ä½œ**ï¼šä½¿ç”¨ Redis Pipeline å’Œ MGET ä¼˜åŒ–æ‰¹é‡è¯»å†™æ€§èƒ½

---

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Go 1.24
- Redis æœåŠ¡
- MySQL/PostgreSQL ç­‰å…³ç³»å‹æ•°æ®åº“

### é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=localhost
DB_PORT=3306
DB_NAME=your_database

# Redis é…ç½®
REDIS_HOST=127.0.0.1
REDIS_PORT=6379

# æœåŠ¡é…ç½®
SERVER_PORT=8080


# Cache Aside Configuration
# TTL when data is loaded from DB and cached (seconds)
CACHE_ASIDE_TTL=11  

# Refresh TTL on cache hit
# true: extend cache lifetime on every read
# false: keep original TTL
CACHE_HIT_REFRESH=false
```

### è¿è¡Œç¤ºä¾‹

```bash
 go run "example\dataConsistency_db_cache_example\ddce_main.go"
```

æœåŠ¡å°†åœ¨ `http://localhost:8080` å¯åŠ¨ã€‚

---

## ç¤ºä¾‹ä»£ç è§£è¯»

- [ç¤ºä¾‹ä»£ç ](./example/dataConsistency_db_cache_example/ddce_main.go)

### æ•´ä½“æ¶æ„

ç¤ºä¾‹ä»£ç é‡‡ç”¨**å››å±‚æ¶æ„**è®¾è®¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. ç¯å¢ƒåˆå§‹åŒ–å±‚ (initEnv)          â”‚  åŠ è½½ .env é…ç½®
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   2. åŸºç¡€è®¾æ–½å±‚ (initInfra)          â”‚  åˆå§‹åŒ– DBã€Redis è¿æ¥
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   3. ä¸šåŠ¡æœåŠ¡å±‚ (initServices)       â”‚  æ„å»º ServiceManager
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   4. HTTP è·¯ç”±å±‚ (initRouter)        â”‚  æ³¨å†Œ API ç«¯ç‚¹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

äº‹å…ˆè¯´æ˜æµç¨‹ï¼š

**1. Cache Aside è¯»æ•°æ®æµç¨‹**
```mermaid
flowchart TD
    A[å®¢æˆ·ç«¯å‘èµ·è¯»ç”¨æˆ·è¯·æ±‚] --> B{æŸ¥Redisç¼“å­˜}
    B -- æœ‰æ•°æ®ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰ --> C[ç›´æ¥è¿”å›æ•°æ®ç»™å®¢æˆ·ç«¯]
    B -- æ— æ•°æ®ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰ --> D[æŸ¥MySQLæ•°æ®åº“]
    D -- æŸ¥åˆ°æ•°æ® --> E[æŠŠæ•°æ®å†™å…¥Redisç¼“å­˜]
    E --> F[è¿”å›æ•°æ®ç»™å®¢æˆ·ç«¯]
    D -- æ²¡æŸ¥åˆ°æ•°æ® --> G[è¿”å›ç©º/é”™è¯¯ç»™å®¢æˆ·ç«¯]
```

**2. ç¼“å­˜â†’æ•°æ®åº“åŒæ­¥æµç¨‹**
```mermaid
flowchart TD
    A[è§¦å‘åŒæ­¥ï¼ˆæ‰‹åŠ¨API/å®šæ—¶ä»»åŠ¡ï¼‰] --> B[æ¥æ”¶åŒæ­¥è¯·æ±‚å‚æ•°]
    B --> C{ä»RedisæŒ‰è§„åˆ™æ‰¹é‡æŸ¥æ•°æ®}
    C -- æ— æ•°æ® --> D[è¿”å›â€œæ— æ•°æ®â€ç»“æœ]
    C -- æœ‰æ•°æ® --> E[æŠŠæ•°æ®æ•´ç†æˆç”¨æˆ·åˆ—è¡¨]
    E --> F[æ‰¹é‡å†™å…¥MySQLï¼ˆå†²çªæ—¶å¯é€‰æ›´æ–°/è·³è¿‡ï¼‰]
    F --> G{æ˜¯å¦éœ€è¦é‡æ–°ç¼“å­˜ï¼Ÿ}
    G -- æ˜¯ --> H[æŠŠæ•°æ®é‡æ–°å†™å…¥Redisï¼ˆå¸¦æœ‰æ•ˆæœŸï¼‰]
    G -- å¦ --> I[ç»“æŸ]
    H --> I[è¿”å›åŒæ­¥ç»“æœï¼ˆæ‰«ææ•°/åŒæ­¥æ•°/è€—æ—¶ï¼‰]
```

**3. ç¨‹åºå¯åŠ¨æ•´ä½“æµç¨‹**
```mermaid
flowchart TD
    A[å¯åŠ¨mainå‡½æ•°] --> B[åŠ è½½.envé…ç½®]
    B --> C[è¿æ¥MySQL+Redis]
    C --> D[åˆ›å»ºç”¨æˆ·æœåŠ¡å¯¹è±¡]
    D --> E[å¯åŠ¨å®šæ—¶åŒæ­¥ä»»åŠ¡ï¼ˆåå°ï¼‰]
    E --> F[æ³¨å†ŒAPIè·¯ç”±]
    F --> G[å¯åŠ¨HTTPæœåŠ¡ï¼Œç›‘å¬ç«¯å£]
```
### å…³é”®ç»„ä»¶è¯´æ˜

#### 1. ç¯å¢ƒåˆå§‹åŒ–å±‚
```go
func initEnv() {
    _ = godotenv.Load()
    // åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
}
```
**èŒè´£**ï¼šä»…è´Ÿè´£åŠ è½½è¿è¡Œç¯å¢ƒï¼Œä¸æ¶‰åŠä»»ä½•ä¸šåŠ¡é€»è¾‘ã€‚

#### 2. åŸºç¡€è®¾æ–½å±‚
```go
func initInfra() (*service.DBManager, *service.RedisManager) {
    dbManager, _ := service.InitDB()
    redisManager, _ := service.InitRedis()
    return dbManager, redisManager
}
```
**èŒè´£**ï¼šåˆ›å»ºæ•°æ®åº“å’Œ Redis è¿æ¥ç®¡ç†å™¨ï¼Œç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾ã€‚

#### 3. ä¸šåŠ¡æœåŠ¡å±‚
```go
func initServices() *service.ServiceManager[model.User] {
    userSvc := service.NewServiceManager(model.User{})
    userSvc.Create(ctx, &service.CreateOptions{IfNotExists: true})
    return userSvc
}
```
**èŒè´£**ï¼šåˆ›å»ºé’ˆå¯¹ `User` æ¨¡å‹çš„ ServiceManagerï¼Œè´Ÿè´£ä¸šåŠ¡é€»è¾‘ä½†ä¸çŸ¥é“ HTTP å±‚ç»†èŠ‚ã€‚

#### 4. HTTP è·¯ç”±å±‚
```go
func initRouter(userSvc *service.ServiceManager[model.User]) *gin.Engine {
    r := gin.Default()
    registerUserWriteRoutes(r, userSvc)   // å†™å…¥è·¯ç”±
    registerUserLookupRoutes(r, userSvc)  // æŸ¥è¯¢è·¯ç”±
    return r
}
```
**èŒè´£**ï¼šå°†ä¸šåŠ¡æœåŠ¡æš´éœ²ä¸º RESTful APIã€‚

### è‡ªå®šä¹‰ä¸šåŠ¡è¿‡æ»¤å™¨ç¤ºä¾‹

```go
func activeUserFilter(
    ctx context.Context,
    client *redis.Client,
    keys []string,
) ([]string, error) {
    // ä½¿ç”¨ Pipeline æ‰¹é‡è·å– status å­—æ®µ
    pipe := client.Pipeline()
    statusCmds := make(map[string]*redis.StringCmd, len(keys))
    
    for _, key := range keys {
        statusCmds[key] = pipe.HGet(ctx, key, "status")
    }
    
    pipe.Exec(ctx)
    
    // ç­›é€‰ status == "1" çš„æ´»è·ƒç”¨æˆ·
    var activeKeys []string
    for key, cmd := range statusCmds {
        if status, _ := cmd.Result(); status == "1" {
            activeKeys = append(activeKeys, key)
        }
    }
    return activeKeys, nil
}
```

### æ•°æ®åº“æ‰¹è½åº“ æ ¸å¿ƒé€»è¾‘ç¤ºä¾‹è®²è§£

```go
// --- æ ¸å¿ƒåŒæ­¥é€»è¾‘ ---
func syncCacheToDatabase(
	ctx context.Context,
	userSvc *service.ServiceManager[model.User],
	req *CacheToDBRequest,
) (*CacheToDBResult, error) {
	startTime := time.Now()
	if req.BatchSize <= 0 {
		req.BatchSize = 500
	}

	// Step 1: ä» Redis æ‰¹é‡è·å–æ•°æ®
	userMap, err := userSvc.LookupQueryByPattern(ctx, req.KeyPattern, &service.LookupQueryOptions{
		FallbackToDB: false,
	})
	if err != nil {
		return nil, fmt.Errorf("lookup failed: %w", err)
	}

	users := make([]model.User, 0, len(userMap))
	for _, u := range userMap {
		if u != nil {
			users = append(users, *u)
		}
	}

	if len(users) == 0 {
		return &CacheToDBResult{
			Duration: time.Since(startTime),
			Mode:     "no_data",
		}, nil
	}

	// Step 2: æ‰¹é‡å†™å…¥æ•°æ®åº“
	err = userSvc.SetQuery(ctx, users, &service.SetQueryOptions{
		BatchSize:        req.BatchSize,
		OnConflictUpdate: req.ConflictStrategy != "skip",
		InvalidateCache:  false,
	})
	if err != nil {
		return nil, fmt.Errorf("db write failed: %w", err)
	}

	result := &CacheToDBResult{
		TotalScanned: len(userMap),
		TotalSynced:  len(users),
		Duration:     time.Since(startTime),
		Mode:         "cache_aside",
	}

	// Step 3: Cache Aside æ¨¡å¼ - è½åº“åé‡æ–°ç¼“å­˜
	if req.RecacheAfterSync {
		recached, err := recacheUsers(ctx, users, getCacheAsideTTL())
		if err != nil {
			log.Printf("Recache warning: %v", err)
		} else {
			result.RecachedItems = recached
			log.Printf("Synced %d items, recached with TTL %v", len(users), getCacheAsideTTL())
		}
	} else {
		log.Printf("Synced %d items to DB", len(users))
	}

	return result, nil
}

// recacheUsers é‡æ–°ç¼“å­˜ç”¨æˆ·æ•°æ®
func recacheUsers(ctx context.Context, users []model.User, ttl time.Duration) (int, error) {
	rdb := service.GetRedis()
	pipe := rdb.Pipeline()

	for _, user := range users {
		key := fmt.Sprintf("user:%d", user.ID)
		jsonData, err := json.Marshal(user)
		if err != nil {
			log.Printf("Marshal error for user %d: %v", user.ID, err)
			continue
		}
		pipe.Set(ctx, key, jsonData, ttl)
	}

	_, err := pipe.Exec(ctx)
	if err != nil {
		return 0, fmt.Errorf("pipeline exec failed: %w", err)
	}

	return len(users), nil
}

// --- é…ç½®è¾…åŠ©å‡½æ•° ---

func getCacheAsideTTL() time.Duration {
	if ttlStr := os.Getenv("CACHE_ASIDE_TTL"); ttlStr != "" {
		if ttl, err := strconv.Atoi(ttlStr); err == nil {
			return time.Duration(ttl) * time.Second
		}
	}
	return 1 * time.Hour
}

func getCacheHitRefresh() bool {
	return os.Getenv("CACHE_HIT_REFRESH") == "true"
}

func getEnvOrDefault(key, defaultValue string) string {
	if v := os.Getenv(key); v != "" {
		return v
	}
	return defaultValue
}

// --- å®šæ—¶åŒæ­¥ä»»åŠ¡ ---

func startPeriodicSync(ctx context.Context, userSvc *service.ServiceManager[model.User]) {
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			log.Println("ğŸ”„ Auto sync...")

			result, err := syncCacheToDatabase(ctx, userSvc, &CacheToDBRequest{
				KeyPattern:       "user:*",
				ConflictStrategy: "upsert",
				RecacheAfterSync: false, // è½åº“åä¸é‡æ–°ç¼“å­˜ï¼Œé¿å…æ— é™åˆ·æ–° TTL
			})

			if err != nil {
				log.Printf("âŒ Sync failed: %v", err)
			} else if result.TotalSynced > 0 {
				log.Printf("Synced: %d items, took: %v (no recache)",
					result.TotalSynced, result.Duration)
			}
		case <-ctx.Done():
			return
		}
	}
}
```
ï¼ˆéœ€è¦è¡¥å……ï¼‰

ä»¥åŠæ•°æ®ä»ç¼“å­˜ä¸­è¯»å–è‡ªå·±æ”¯æŒcache-asideï¼Œä¸‹é¢æ˜¯cache-asideçš„è®²è§£ï¼š

### cache-asideçš„è®²è§£

```go

// ========== æ ¸å¿ƒæŸ¥è¯¢é€»è¾‘ ==========

func (lrg *LookupRouterGroup[T]) executeLookup(
	ctx context.Context,
	keyPattern string,
	filters []filter_translator.FilterParam,
	useCustomFilter bool,
	fallbackToDB bool,
) (map[string]*T, []string, error) {

	// 1. è·å–æ‰€æœ‰åŒ¹é…çš„é”®
	redisClient := service.GetRedis()
	allKeys, err := redisClient.Keys(ctx, keyPattern).Result()
	if err != nil {
		return nil, nil, fmt.Errorf("failed to get keys: %w", err)
	}

	// 2. åº”ç”¨è‡ªå®šä¹‰è¿‡æ»¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if useCustomFilter && lrg.customFilterFunc != nil {
		allKeys, err = lrg.customFilterFunc(ctx, redisClient, allKeys)
		if err != nil {
			return nil, nil, fmt.Errorf("custom filter failed: %w", err)
		}
	}

	// 3. ç¿»è¯‘å¹¶åº”ç”¨é€šç”¨è¿‡æ»¤å™¨
	if len(filters) > 0 {
		redisFilters, err := lrg.TranslatorRegistry.TranslateBatch(filters)
		if err != nil {
			return nil, nil, fmt.Errorf("invalid filters: %w", err)
		}

		allKeys, err = filter_translator.ApplyRedisFilters(ctx, redisClient, allKeys, redisFilters)
		if err != nil {
			return nil, nil, fmt.Errorf("filter application failed: %w", err)
		}
	}

	// åªä¿ç•™æ™®é€šå¯¹è±¡ key
	filteredKeys := make([]string, 0, len(allKeys))
	for _, k := range allKeys {
		if !strings.HasSuffix(k, ":version") && !strings.HasSuffix(k, ":meta") {
			filteredKeys = append(filteredKeys, k)
		}
	}
	allKeys = filteredKeys

	// å¦‚æœ Redis æ²¡æœ‰æ•°æ®
	// 1. æœ‰ filters æ—¶ï¼Œæ€»æ˜¯ä» DB æŸ¥è¯¢ï¼ˆå› ä¸ºå¯èƒ½ç¼“å­˜ä¸­æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼‰
	// 2. æ—  filters ä¸” fallback_db=true æ—¶ï¼Œä» DB åŠ è½½æ‰€æœ‰æ•°æ®
	if len(allKeys) == 0 {
		if len(filters) > 0 || fallbackToDB {
			return lrg.loadFromDBAndCache(ctx, keyPattern, filters)
		}
		return make(map[string]*T), []string{}, nil
	}

	// 4. ä»ç¼“å­˜æŸ¥è¯¢æ•°æ®
	opts := &service.LookupQueryOptions{
		KeyPattern:   keyPattern,
		CacheExpire:  lrg.defaultCacheExpire,
		FallbackToDB: fallbackToDB,
	}

	result, err := lrg.Service.LookupQuery(ctx, allKeys, opts)
	if err != nil {
		return nil, nil, fmt.Errorf("lookup query failed: %w", err)
	}

	return result, allKeys, nil
}

// loadFromDBAndCache ä»æ•°æ®åº“åŠ è½½æ•°æ®å¹¶å†™å…¥ç¼“å­˜ï¼ˆæ”¯æŒæ¡ä»¶æŸ¥è¯¢ï¼‰
func (lrg *LookupRouterGroup[T]) loadFromDBAndCache(
	ctx context.Context,
	keyPattern string,
	filters []filter_translator.FilterParam,
) (map[string]*T, []string, error) {
	// å°† Redis filters è½¬æ¢ä¸º GORM æŸ¥è¯¢æ¡ä»¶
	var queryFunc func(*gorm.DB) *gorm.DB

	if len(filters) > 0 {
		gormFilters, err := filter_translator.DefaultGormRegistry.TranslateBatch(filters)
		if err != nil {
			return nil, nil, fmt.Errorf("invalid gorm filters: %w", err)
		}

		queryFunc = func(db *gorm.DB) *gorm.DB {
			return filter_translator.ApplyGormFilters(db, gormFilters)
		}
	}
	// ä»æ•°æ®åº“æŸ¥è¯¢æ•°æ®
	queryResult, err := lrg.Service.GetQueryWithoutTransaction(ctx, queryFunc, nil)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to query from database: %w", err)
	}

	if len(queryResult.Data) == 0 {
		return make(map[string]*T), []string{}, nil
	}

	// æ‰¹é‡å†™å…¥ç¼“å­˜
	rdb := service.GetRedis()
	pipe := rdb.Pipeline()

	resultMap := make(map[string]*T)
	keys := make([]string, 0, len(queryResult.Data))

	for i := range queryResult.Data {
		item := &queryResult.Data[i]

		// åºåˆ—åŒ–ä¸º JSON
		jsonData, err := json.Marshal(item)
		if err != nil {
			continue
		}

		// ä» JSON ä¸­æå– IDï¼ˆé€šç”¨æ–¹æ³•ï¼‰
		var tempMap map[string]interface{}
		if err := json.Unmarshal(jsonData, &tempMap); err != nil {
			continue
		}

		id, ok := tempMap["id"].(float64) // JSON æ•°å­—é»˜è®¤æ˜¯ float64
		if !ok {
			continue
		}

		key := fmt.Sprintf("user:%d", uint(id))

		// å†™å…¥ Pipeline
		pipe.Set(ctx, key, jsonData, lrg.cacheAsideTTL)

		resultMap[key] = item
		keys = append(keys, key)
	}

	// æ‰§è¡Œæ‰¹é‡å†™å…¥
	if len(keys) > 0 {
		if _, err := pipe.Exec(ctx); err != nil {
			// å³ä½¿ç¼“å­˜å¤±è´¥ï¼Œä¹Ÿè¿”å›æ•°æ®åº“æ•°æ®
			return resultMap, keys, nil
		}
	}

	return resultMap, keys, nil
}

// ========== Cache Aside æ¨¡å¼æ ¸å¿ƒé€»è¾‘ ==========

// extractIDFromKey ä» Redis key ä¸­æå– ID (ä¾‹å¦‚ "user:123" -> 123)
func (lrg *LookupRouterGroup[T]) extractIDFromKey(key string) (uint, error) {
	parts := strings.Split(key, ":")
	if len(parts) < 2 {
		return 0, fmt.Errorf("invalid key format: %s", key)
	}
	id, err := strconv.ParseUint(parts[len(parts)-1], 10, 32)
	if err != nil {
		return 0, fmt.Errorf("failed to parse ID from key %s: %w", key, err)
	}
	return uint(id), nil
}

// getByKeyCacheAside å®ç° Cache Aside æ¨¡å¼çš„å•ä¸ªé”®æŸ¥è¯¢
// 1. å…ˆæŸ¥ Redis
// 2. å¦‚æœå‘½ä¸­ï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ·æ–° TTL
// 3. å¦‚æœæœªå‘½ä¸­ï¼šä» DB æŸ¥è¯¢ï¼Œè½¬ä¸º JSONï¼Œå†™å…¥ Redisï¼Œè®¾ç½® TTL
func (lrg *LookupRouterGroup[T]) getByKeyCacheAside(ctx context.Context, key string) (*T, bool, error) {
	redisClient := service.GetRedis()

	// Step 1: å°è¯•ä» Redis è·å–
	var result T
	val, err := redisClient.Get(ctx, key).Result()

	if err == nil {
		// Cache Hit
		if err := json.Unmarshal([]byte(val), &result); err != nil {
			return nil, false, fmt.Errorf("failed to unmarshal cached data: %w", err)
		}

		// æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ·æ–° TTL
		if lrg.cacheHitRefresh {
			redisClient.Expire(ctx, key, lrg.cacheAsideTTL)
		}

		return &result, true, nil
	}

	if err != redis.Nil {
		// Redis é”™è¯¯ï¼ˆé key ä¸å­˜åœ¨ï¼‰
		return nil, false, fmt.Errorf("redis get error: %w", err)
	}

	// Step 2: Cache Miss - ä»æ•°æ®åº“æŸ¥è¯¢
	id, err := lrg.extractIDFromKey(key)
	if err != nil {
		return nil, false, err
	}

	// ä½¿ç”¨ ServiceManager çš„ GetQueryWithoutTransaction æŸ¥è¯¢å•æ¡æ•°æ®
	queryResult, err := lrg.Service.GetQueryWithoutTransaction(
		ctx,
		func(db *gorm.DB) *gorm.DB {
			return db.Where("id = ?", id)
		},
		nil,
	)

	if err != nil {
		return nil, false, fmt.Errorf("failed to query from database: %w", err)
	}

	if len(queryResult.Data) == 0 {
		// æ•°æ®åº“ä¸­ä¹Ÿä¸å­˜åœ¨
		return nil, false, fmt.Errorf("record not found for key: %s", key)
	}

	result = queryResult.Data[0]

	// Step 3: å°†æ•°æ®è½¬ä¸º JSON å¹¶å†™å…¥ Redis
	jsonData, err := json.Marshal(result)
	if err != nil {
		return &result, false, fmt.Errorf("failed to marshal data: %w", err)
	}

	// å†™å…¥ Redis å¹¶è®¾ç½® TTL
	err = redisClient.Set(ctx, key, jsonData, lrg.cacheAsideTTL).Err()
	if err != nil {
		// å³ä½¿å†™å…¥ Redis å¤±è´¥ï¼Œä¹Ÿè¿”å›æ•°æ®åº“ä¸­çš„æ•°æ®
		return &result, false, fmt.Errorf("failed to cache data (returned DB data): %w", err)
	}

	return &result, false, nil
}
```
ï¼ˆéœ€è¦è¡¥å……ï¼‰

---

## API æ¥å£è¯¦è§£

### API ç”±æ¥ä¸è®¾è®¡ç†å¿µ

æ¡†æ¶é€šè¿‡ `WritedownRouterGroup` å’Œ `LookupRouterGroup` ä¸¤ä¸ªç»„ä»¶è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†åŒ–çš„ RESTful API,å³åªè¦ä½¿ç”¨äº†è¿™ä¸¤ä¸ªæ–¹æ³•ï¼Œé‚£ä¹ˆapiéƒ½æ˜¯åœ¨è‡ªå®šä¹‰çš„åŸºç¡€ä¸Šå›ºå®šå…³é”®éƒ¨åˆ†ï¼š

- **WritedownRouterGroup**ï¼šç®¡ç†æ‰€æœ‰å†™å…¥æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ã€ç¼“å­˜å†™å…¥ï¼‰
- **LookupRouterGroup**ï¼šç®¡ç†æ‰€æœ‰æŸ¥è¯¢æ“ä½œï¼ˆæ¡ä»¶æŸ¥è¯¢ã€ç¼“å­˜èšåˆæŸ¥è¯¢ï¼‰

è¿™ç§è®¾è®¡è®©å¼€å‘è€…**æ— éœ€æ‰‹å†™è·¯ç”±å¤„ç†å‡½æ•°**ï¼Œåªéœ€é…ç½® ServiceManager å³å¯è·å¾—å®Œæ•´çš„ CRUD APIã€‚

### å‰åç«¯äº¤äº’æ¡†æ¶çº¦æŸ

#### ç»Ÿä¸€å“åº”æ ¼å¼

æ‰€æœ‰ API å“åº”éµå¾ªä»¥ä¸‹ç»“æ„ï¼š

```json
{
    "code": 0,              // 0 è¡¨ç¤ºæˆåŠŸï¼Œé 0 è¡¨ç¤ºé”™è¯¯
    "message": "success",   // æ“ä½œç»“æœæè¿°
    "data": {},             // å…·ä½“æ•°æ®ï¼ˆæŸ¥è¯¢æ¥å£è¿”å›ï¼‰
    "keys": [],             // è¿”å›çš„ key åˆ—è¡¨ï¼ˆæŸ¥è¯¢æ¥å£ï¼‰
    "count": 0,             // æ•°æ®æ¡æ•°ï¼ˆæŸ¥è¯¢æ¥å£ï¼‰
    "items_written": 0      // å†™å…¥æ¡æ•°ï¼ˆå†™å…¥æ¥å£ï¼‰
}
```

### å†™å…¥æ¥å£ (Write Operations)

#### 1. æ‰¹é‡å†™å…¥ç¼“å­˜
**ç«¯ç‚¹**ï¼š`POST /api/v1/users/cache/batch-write`

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
    "key_template": "user:{id}",
    "data": [
        {"id": 1001, "username": "asdf", "email": "asdf@example.com"},
        {"id": 1002, "username": "fdsa", "email": "fdaa@example.com"}
    ],
    "expiration": 1800,
    "batch_size": 100
}
```

**å‚æ•°è¯´æ˜**ï¼š
- `key_template`ï¼šRedis key æ¨¡æ¿ï¼Œ`{id}` ä¼šè¢«æ›¿æ¢ä¸ºå®é™… ID
- `data`ï¼šè¦å†™å…¥çš„æ•°æ®æ•°ç»„
- `expiration`ï¼šè¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
- `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
    "code": 0,
    "message": "success",
    "items_written": 2
}
```

#### 2. ç‰ˆæœ¬åŒ–å†™å…¥
**ç«¯ç‚¹**ï¼š`POST /api/v1/users/cache/write-version`

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
    "key": "user:1006",
    "data": {
        "id": 1003,
        "username": "sukasuka",
        "email": "sukasuka@example.com",
        "age": 18
    },
    "version": 5,
    "expiration": 3600
}
```

**ç‰¹æ€§**ï¼šæ”¯æŒä¹è§‚é”ï¼Œåªæœ‰ç‰ˆæœ¬å·åŒ¹é…æ—¶æ‰å†™å…¥æˆåŠŸã€‚

#### 3. æ™®é€šå†™å…¥
**ç«¯ç‚¹**ï¼š`POST /api/v1/users/cache/write`

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
    "key": "user:1007",
    "data": {
        "id": 1001,
        "username": "seven",
        "email": "seven@example.com",
        "age": 25
    },
    "expiration": 3600,
    "overwrite": true
}
```

**å‚æ•°è¯´æ˜**ï¼š
- `overwrite`ï¼šæ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„ key

### æŸ¥è¯¢æ¥å£ (Lookup Operations)

#### åŸºç¡€æŸ¥è¯¢
**ç«¯ç‚¹**ï¼š`POST /api/v1/users/lookup/lookup`

**è¯·æ±‚ç¤ºä¾‹ 1ï¼šæŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·**
```json
{
    "key_pattern": "user:*",
    "filters": [],
    "use_custom_filter": false,
    "fallback_db": false
}
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
    "code": 0,
    "message": "success",
    "data": {
        "user:1001": {
            "id": 1001,
            "username": "asdf",
            "email": "asdf@example.com",
            "age": 21
        },
        "user:1002": {
            "id": 1002,
            "username": "fdsa",
            "email": "fdaa@example.com",
            "age": 22
        }
    },
    "keys": ["user:1001", "user:1002"],
    "count": 2
}
```

**è¯·æ±‚ç¤ºä¾‹ 2ï¼šå¸¦æ¡ä»¶è¿‡æ»¤**
```json
{
    "key_pattern": "user:*",
    "filters": [
        {"field": "age", "operator": "<", "value": 24},
        {"field": "age", "operator": ">=", "value": 21}
    ],
    "use_custom_filter": false,
    "fallback_db": false
}
```
æˆ–è€…
```json
{
  "key_pattern": "user:*",
  "filters": [
    {
      "field": "age",
      "operator": "between",
      "value": [21, 23]
    }
  ],
  "use_custom_filter": false,
  "fallback_db": false
}
```
**å“åº”ç¤ºä¾‹**ï¼š
```json
{
    "code": 0,
    "message": "success",
    "data": {
        "user:1001": {
            "id": 1001,
            "username": "asdf",
            "email": "asdf@example.com",
            "age": 21,
            "created_at": "0001-01-01T00:00:00Z",
            "updated_at": "0001-01-01T00:00:00Z"
        },
        "user:1002": {
            "id": 1002,
            "username": "fdsa",
            "email": "fdaa@example.com",
            "age": 22,
            "created_at": "0001-01-01T00:00:00Z",
            "updated_at": "0001-01-01T00:00:00Z"
        },
        "user:1003": {
            "id": 1003,
            "username": "asdff",
            "email": "asdff@example.com",
            "age": 23,
            "created_at": "0001-01-01T00:00:00Z",
            "updated_at": "0001-01-01T00:00:00Z"
        }
    },
    "keys": [
        "user:1001",
        "user:1002",
        "user:1003"
    ],
    "count": 3
}
```

**å‚æ•°è¯´æ˜**ï¼š
- `key_pattern`ï¼šRedis key åŒ¹é…æ¨¡å¼ï¼ˆæ”¯æŒ `*` é€šé…ç¬¦ï¼‰
- `filters`ï¼šè¿‡æ»¤æ¡ä»¶æ•°ç»„ï¼ˆå¤šä¸ªæ¡ä»¶ä¸º AND å…³ç³»ï¼‰
- `use_custom_filter`ï¼šæ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰ä¸šåŠ¡è¿‡æ»¤å™¨ï¼ˆå¦‚ `activeUserFilter`ï¼‰
- `fallback_db`ï¼šç¼“å­˜æœªå‘½ä¸­æ—¶æ˜¯å¦å›æºæ•°æ®åº“

---

## è¿‡æ»¤å™¨ç³»ç»Ÿ

### è¿‡æ»¤å™¨æ¶æ„

æ¡†æ¶æä¾›äº†ç»Ÿä¸€çš„è¿‡æ»¤å™¨ç¿»è¯‘æœºåˆ¶ï¼Œå°†å‰ç«¯ä¼ å…¥çš„è¿‡æ»¤æ¡ä»¶è‡ªåŠ¨è½¬æ¢ä¸º Redis æˆ–æ•°æ®åº“æŸ¥è¯¢ï¼š

```
å‰ç«¯ JSON è¿‡æ»¤æ¡ä»¶  â†’  FilterParam  â†’  FilterTranslator  â†’  RedisFilter  â†’  æ‰§è¡Œè¿‡æ»¤
```

### æ”¯æŒçš„è¿‡æ»¤æ“ä½œç¬¦å¯¹ç…§è¡¨

| æ“ä½œç¬¦ | å«ä¹‰ | ç¤ºä¾‹ | è¯´æ˜ |
|--------|------|------|------|
| `=` | ç­‰äº | `{"field": "age", "operator": "=", "value": 25}` | ç²¾ç¡®åŒ¹é… |
| `!=` | ä¸ç­‰äº | `{"field": "status", "operator": "!=", "value": "inactive"}` | æ’é™¤æŒ‡å®šå€¼ |
| `>` | å¤§äº | `{"field": "age", "operator": ">", "value": 18}` | æ•°å€¼æ¯”è¾ƒ |
| `>=` | å¤§äºç­‰äº | `{"field": "score", "operator": ">=", "value": 60}` | æ•°å€¼æ¯”è¾ƒï¼ˆå«è¾¹ç•Œï¼‰ |
| `<` | å°äº | `{"field": "age", "operator": "<", "value": 30}` | æ•°å€¼æ¯”è¾ƒ |
| `<=` | å°äºç­‰äº | `{"field": "price", "operator": "<=", "value": 100}` | æ•°å€¼æ¯”è¾ƒï¼ˆå«è¾¹ç•Œï¼‰ |
| `like` | æ¨¡ç³ŠåŒ¹é… | `{"field": "username", "operator": "like", "value": "john"}` | å­—ç¬¦ä¸²åŒ…å«ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ |
| `in` | åœ¨é›†åˆä¸­ | `{"field": "id", "operator": "in", "value": [1, 2, 3]}` | åŒ¹é…å¤šä¸ªå€¼ä¹‹ä¸€ |
| `between` | åŒºé—´èŒƒå›´ | `{"field": "age", "operator": "between", "value": [18, 30]}` | é—­åŒºé—´ [min, max] |
| `isnull` | ä¸ºç©º | `{"field": "deleted_at", "operator": "isnull"}` | å­—æ®µå€¼ä¸º null |
| `isnotnull` | ä¸ä¸ºç©º | `{"field": "email", "operator": "isnotnull"}` | å­—æ®µå€¼é null |

### è¿‡æ»¤å™¨å®ç°åŸç†

#### æ‰¹é‡ä¼˜åŒ–ç­–ç•¥

æ¡†æ¶ä½¿ç”¨ **MGET + JSON è§£æ** çš„æ–¹å¼å®ç°é«˜æ€§èƒ½æ‰¹é‡è¿‡æ»¤ï¼š

```go
func applyRedisBatchFilter(...) ([]string, error) {
    // 1. ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ key çš„å€¼ï¼ˆé¿å… N æ¬¡ç½‘ç»œè¯·æ±‚ï¼‰
    values, _ := client.MGet(ctx, keys...).Result()
    
    // 2. åœ¨å†…å­˜ä¸­è§£æ JSON å¹¶åº”ç”¨è¿‡æ»¤é€»è¾‘
    for i, val := range values {
        var data map[string]interface{}
        json.Unmarshal([]byte(val.(string)), &data)
        
        // æå–å­—æ®µå€¼å¹¶åº”ç”¨è¿‡æ»¤å‡½æ•°
        if filterFunc(data[field]) {
            result = append(result, keys[i])
        }
    }
    return result, nil
}
```

**æ€§èƒ½ä¼˜åŠ¿**ï¼š
- ä½¿ç”¨ MGET æ›¿ä»£å¤šæ¬¡ GETï¼Œå‡å°‘ç½‘ç»œå¾€è¿”
- å†…å­˜è¿‡æ»¤é¿å… Redis Lua è„šæœ¬å¤æ‚æ€§
- æ”¯æŒå¤æ‚ JSON ç»“æ„çš„å­—æ®µæå–

#### æ•°æ®ç»“æ„åµŒå¥—æ”¯æŒ

è¿‡æ»¤å™¨æ”¯æŒä¸¤å±‚ JSON ç»“æ„ï¼š

```json
// é¡¶å±‚å­—æ®µ
{"id": 1001, "age": 25}

// åµŒå¥—åœ¨ data å­—æ®µä¸­
{"data": {"id": 1001, "age": 25}}
```

æå–é€»è¾‘ä¼šä¼˜å…ˆæŸ¥æ‰¾é¡¶å±‚ï¼Œè‹¥æ— åˆ™å°è¯• `data` åµŒå¥—å­—æ®µã€‚

### å¤šæ¡ä»¶ç»„åˆç¤ºä¾‹

```json
{
  "key_pattern": "user:*",
  "filters": [
    {
      "field": "age",
      "operator": "<",
      "value": 24
    },
    {
      "field": "age",
      "operator": ">",
      "value": 21
    }
  ],
  "use_custom_filter": false,
  "fallback_db": false
}
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. ä½¿ç”¨ `key_pattern` åŒ¹é…æ‰€æœ‰ç¬¦åˆçš„ key
2. ä¾æ¬¡åº”ç”¨æ¯ä¸ªè¿‡æ»¤å™¨ï¼ˆAND å…³ç³»ï¼‰
3. è¿”å›æœ€ç»ˆç¬¦åˆæ‰€æœ‰æ¡ä»¶çš„ key å’Œæ•°æ®

---

## æœªæ¥ç¤ºä¾‹è®²è§£é¢„å‘Šï¼ŒåŠŸèƒ½ä¸Šå®ç°ä½†æ˜¯éœ€è¦å†™ç¤ºä¾‹ä»£ç 

### 1. ç¼“å­˜æ‰¹é‡è½åº“ï¼ˆCache Write-Throughï¼‰

**åŠŸèƒ½æè¿°**ï¼šå°† Redis ç¼“å­˜ä¸­çš„æ•°æ®æ‰¹é‡åŒæ­¥åˆ°æ•°æ®åº“ï¼Œæ”¯æŒå¢é‡å’Œå…¨é‡åŒæ­¥ã€‚

**é¢„æœŸ API**ï¼š
```json
POST /api/v1/users/sync/cache-to-db
{
    "key_pattern": "user:*",
    "batch_size": 500,
    "conflict_strategy": "upsert"  // upsert | skip | overwrite
}
```

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ Redis SCAN æ¸¸æ ‡éå†é¿å…é˜»å¡
- æ‰¹é‡ INSERT/UPDATE ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½
- æ”¯æŒå†²çªè§£å†³ç­–ç•¥ï¼ˆè¦†ç›–ã€è·³è¿‡ã€æ›´æ–°ï¼‰

### 2. æ•°æ®åº“å›æ»šåˆ°ç¼“å­˜ï¼ˆDB Read-Throughï¼‰

**åŠŸèƒ½æè¿°**ï¼šä»æ•°æ®åº“åŠ è½½æ•°æ®å¹¶é‡å»º Redis ç¼“å­˜ï¼Œæ”¯æŒå…¨é‡å’Œå¢é‡é¢„çƒ­ã€‚

**é¢„æœŸ API**ï¼š
```json
POST /api/v1/users/sync/db-to-cache
{
    "filters": [
        {"field": "created_at", "operator": ">", "value": "2024-01-01"}
    ],
    "key_template": "user:{id}",
    "expiration": 3600,
    "batch_size": 1000
}
```

**å®ç°è¦ç‚¹**ï¼š
- åˆ†æ‰¹ä»æ•°æ®åº“è¯»å–æ•°æ®ï¼ˆé¿å… OOMï¼‰
- ä½¿ç”¨ Redis Pipeline æ‰¹é‡å†™å…¥
- æ”¯æŒè¿›åº¦è·Ÿè¸ªå’Œæ–­ç‚¹ç»­ä¼ 

### 3. ç¼“å­˜ä¸€è‡´æ€§ä¿éšœ

**åŠŸèƒ½æè¿°**ï¼šç›‘å¬æ•°æ®åº“å˜æ›´äº‹ä»¶ï¼ˆå¦‚ Binlogï¼‰ï¼Œè‡ªåŠ¨æ›´æ–° Redis ç¼“å­˜ã€‚

**æŠ€æœ¯æ–¹æ¡ˆ**ï¼š
- é›†æˆ Debezium æˆ– Canal ç›‘å¬ MySQL Binlog
- å®æ—¶æ¨é€å˜æ›´åˆ° Redis
- æ”¯æŒå»¶è¿Ÿåˆ é™¤å’Œç‰ˆæœ¬å·æ ¡éªŒ

---

## æ€»ç»“

AbstractManager æ¡†æ¶é€šè¿‡åˆ†å±‚æ¶æ„å’Œç»Ÿä¸€æŠ½è±¡ï¼Œå¤§å¹…ç®€åŒ–äº†ç¼“å­˜ç®¡ç†çš„å¤æ‚åº¦ã€‚å¼€å‘è€…åªéœ€ï¼š

1. å®šä¹‰æ•°æ®æ¨¡å‹ï¼ˆå¦‚ `User`ï¼‰
2. åˆ›å»º `ServiceManager`
3. æ³¨å†Œè·¯ç”±ç»„

å³å¯è·å¾—å®Œæ•´çš„ç¼“å­˜ CRUD API å’Œå¼ºå¤§çš„è¿‡æ»¤æŸ¥è¯¢èƒ½åŠ›ï¼Œä»¥åŠæ ¹æ®cache-asideçš„ç¤ºä¾‹å¯ä»¥ç»™å‡ºç»å¤§éƒ¨åˆ†çš„åŸå‹åç«¯å®ç°ã€‚æ¡†æ¶çš„è¿‡æ»¤å™¨ç³»ç»Ÿé€šè¿‡é«˜æ€§èƒ½æ‰¹é‡æ“ä½œå’Œçµæ´»çš„æ“ä½œç¬¦æ”¯æŒï¼Œæ»¡è¶³äº†å¤æ‚ä¸šåŠ¡åœºæ™¯çš„éœ€æ±‚ã€‚

æœªæ¥ç‰ˆæœ¬å°†å¢å¼ºç¼“å­˜ä¸æ•°æ®åº“çš„åŒå‘åŒæ­¥èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥æå‡æ•°æ®ä¸€è‡´æ€§å’Œç³»ç»Ÿå¯é æ€§ã€‚

## æƒ…å†µè¯´æ˜

ä¸»åŒ…ç°è¦å»æ˜†æ˜è€å¦ˆå®¶é‚£è¾¹è¿‡æ˜¥èŠ‚ï¼Œæ‰€ä»¥å¾ˆå¤šæ—¶å€™ä¸èƒ½åŠæ—¶æ›´æ–°ã€‚æ˜¥èŠ‚ä¹‹åä¼šæ­£å¸¸æ›´æ–°è¯¥æ¡†æ¶çš„ç¤ºä¾‹ä»£ç ä»¥åŠæ ¹æ®ç¤ºä¾‹ä»£ç æ”¹è¿›æ¡†æ¶ä»£ç ã€‚
